{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Cross Validation & Naive Bayes Lab - SMS Spam Classification\n",
    "===============\n",
    "orignally developed by Ankit Jain\n",
    "modified by Justin Breucop\n",
    "\n",
    "Data source: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Cross Validation from Scratch\n",
    "\n",
    "Let's build it the function together! The steps to cross validation are:\n",
    "1. Randomly separate your training set into _k_ groups\n",
    "2. For each group _k_:\n",
    ">1. Train your model on the other groups\n",
    ">2. Score your model using gorup _k_ as validation\n",
    ">3. Save your score and move to your next group\n",
    "\n",
    "3. Add your _k_ scores and divide by _k_ to get your average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing Packages \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_neighbors=10, p=2, weights='uniform')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(10)\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_csv('titanic-train.csv', index_col=None)#[['Age','Pclass','SibSp', 'Survived']].dropna()\n",
    "to_predict = 'Survived'\n",
    "features = ['Age', 'Pclass', 'SibSp']\n",
    "data = df[features].dropna()\n",
    "#data=df[features]\n",
    "label = df[to_predict]\n",
    "folds=5\n",
    "\n",
    "data\n",
    "to_predict\n",
    "label\n",
    "df\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 714 entries, 0 to 890\n",
      "Data columns (total 3 columns):\n",
      "Age       714 non-null float64\n",
      "Pclass    714 non-null int64\n",
      "SibSp     714 non-null int64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 22.3 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.describe()\n",
    "#label.describe()\n",
    "data.info()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([432, 854, 331, 587, 441,  66, 407, 858, 268, 116, 528, 586, 321,\n",
       "       720, 283, 385, 595, 654, 569, 570, 638, 429, 162, 133,  69, 886,\n",
       "       480, 833, 512, 346, 123, 316, 135, 458, 608, 579, 733, 320, 558,\n",
       "       870, 282, 855, 848, 649, 353,  68, 412, 549, 770, 550, 713, 112,\n",
       "       651, 171, 742, 702, 259,  38, 762, 299, 882, 115, 496,   6, 127,\n",
       "       764, 574, 743, 272, 380, 373, 609, 672, 805, 155, 386, 816, 105,\n",
       "       370, 136, 362, 736, 660, 396, 350, 876, 488, 382, 777, 460, 641,\n",
       "       501, 500, 252, 194, 302, 224, 631, 130, 478, 479, 818, 271, 577,\n",
       "       755,  41, 200, 619, 484, 215, 228, 338,  12, 681, 555,  61, 806,\n",
       "       357, 566,  14, 683, 296, 553, 503,  85, 706, 258, 789, 157, 827,\n",
       "       211, 120, 830, 376, 708,  74, 217, 675, 418, 145, 753, 151, 489,\n",
       "       799, 544, 691, 403, 433, 661, 294, 421, 216, 205, 293, 567, 726,\n",
       "         7, 562, 748, 530,  10, 278, 202, 521, 710, 841, 352, 195, 230,\n",
       "        59, 199,  11, 786, 690, 819, 275, 183, 798, 721, 745, 515, 423,\n",
       "       509, 153, 795,  22, 823, 426, 666, 182, 332, 617, 360, 862, 343,\n",
       "       189, 510, 247, 242, 779, 838, 889, 724,  44, 243, 471, 635, 687,\n",
       "       700, 731,  49, 417, 164, 348,  72, 344, 784, 387, 704, 150, 664,\n",
       "        58, 757, 100, 374, 658, 137,  86, 504, 342, 172, 336, 686, 591,\n",
       "       179, 108, 556, 473, 422, 345, 767, 857, 146, 594, 371, 523, 671,\n",
       "       618, 319, 622, 467, 890, 534, 744,  13, 746,  98, 103, 290, 390,\n",
       "       725, 765, 167, 782, 238, 856, 487,  80, 885, 329, 831, 800,  20,\n",
       "       821, 379, 682, 266, 853,  88, 161, 292, 604, 482, 143, 394, 607,\n",
       "       787, 455, 676, 756,   1, 494, 400, 810, 636, 689, 236,   2, 249,\n",
       "       871, 505, 679, 317, 621,  99, 881, 142, 769, 391, 780, 363, 366,\n",
       "       430, 652, 285, 312, 401, 657, 536, 209, 333, 469, 539,  78, 188,\n",
       "       813, 628, 328, 203, 462, 498, 148,  89, 774, 812, 797, 261, 355,\n",
       "       701, 843, 104, 244, 448, 741, 865, 603, 824, 873, 545, 575, 814,\n",
       "       749, 156, 585, 435, 840, 437, 771,  34, 438, 796, 408,  70, 642,\n",
       "       297, 204, 279, 803, 402, 866, 872, 309, 392, 222, 623, 327, 535,\n",
       "        91, 210,  52, 737, 728, 427, 255, 729, 678, 698, 356, 491, 551,\n",
       "       712, 447, 218,  96, 456, 600, 288, 794, 399, 630,  73, 318, 307,\n",
       "       226, 286, 289, 884, 715, 576, 677, 414, 869, 516,  25, 184, 308,\n",
       "       809, 606, 506, 106,  93, 788,  37, 377, 877, 804, 273, 248, 670,\n",
       "       752, 477, 685, 395, 532, 110, 113, 513, 526, 173, 129,  30, 139,\n",
       "       213, 719, 529, 624, 197, 864, 836, 684,  71, 763, 207,   4, 716,\n",
       "       829, 874, 245, 267, 879,  27, 599, 237, 187, 561,  90, 190, 165,\n",
       "       193, 835, 688,  39, 751, 434, 474, 632,  63, 398, 372, 144, 452,\n",
       "       322, 174, 118,  75, 405, 439, 152, 662, 750, 269, 436, 263, 310,\n",
       "       311, 695,  62, 861, 582, 842, 610, 754,  81, 227, 559, 262, 492,\n",
       "       341, 493, 419, 775, 820, 614, 147, 694, 499, 314, 665, 483, 696,\n",
       "       257,  79, 163, 734, 416, 225, 781,  50, 834, 219,  15, 663, 476,\n",
       "       280, 791, 705, 605, 817, 850, 537, 119, 253, 239, 175, 735, 254,\n",
       "         9, 627, 785, 287, 747, 543, 124, 571, 221, 450, 626, 339, 323,\n",
       "        67, 378, 717, 233, 668, 615, 291, 801,  83, 860, 131,  56, 313,\n",
       "        23, 655, 111, 554, 251,   0, 446, 208, 699, 822, 138, 761, 580,\n",
       "       588, 381,  97, 440, 453, 808, 880, 514, 659,  18, 887, 114, 645,\n",
       "       220, 572, 281, 365, 102, 883, 325, 192, 361, 212, 424, 178, 597,\n",
       "       851, 442,  21, 640, 540, 340,  51, 393, 134, 246,  53,  84, 315,\n",
       "       122, 802,  16, 326, 383, 170, 519, 616, 583,  24, 276, 541, 634,\n",
       "       265, 673, 389, 875, 463, 546, 508, 625, 520, 461, 486, 722,  60,\n",
       "       592, 730,  92, 141, 472, 714, 852, 117, 132, 723, 206, 772, 548,\n",
       "       518, 397, 445, 337, 404, 525, 234, 125, 867,   8, 443,  94, 169,\n",
       "       177, 191, 305,  35, 406, 807, 349, 160, 590, 581, 231, 847,  54,\n",
       "       707,  57, 811, 565, 647, 693, 232, 644,  33, 759, 758, 637, 844,\n",
       "       149, 703, 465, 620, 845,  43,   3, 449, 369,  40, 542, 646], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = data.index.values\n",
    "positions\n",
    "shuffled = np.random.shuffle(positions)\n",
    "positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build in class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function here\n",
    "\n",
    "def crossValidateScoreDataFrame(data, label, model, folds):\n",
    "\n",
    "    positions = data.index.values\n",
    "    np.random.shuffle(positions)\n",
    "\n",
    "    test_slices = []\n",
    "    train_slices = []\n",
    "\n",
    "    for i in range(folds):\n",
    "\n",
    "        \n",
    "        pos_var = len(data)/folds\n",
    "        test_slice = positions[i*pos_var:(i+1)*pos_var]\n",
    "        train_1 = positions[ :i*pos_var]\n",
    "        train_2 = positions[(i+1)*pos_var:]\n",
    "        train_slice = np.concatenate([train_1, train_2])\n",
    "\n",
    "        test_slices.append(test_slice)\n",
    "        train_slices.append(train_slice)\n",
    "\n",
    "        #print test_slice\n",
    "        print len(train_slice)\n",
    "    \n",
    "    print test_slices\n",
    "   \n",
    "    cv_score = 0\n",
    "    for train_k, test_k in zip(train_slices, test_slices):\n",
    "        model.fit(data.loc[train_k], label.loc[train_k])\n",
    "        fold_score = model.score(data.loc[test_k], label.loc[test_k])\n",
    "\n",
    "        print fold_score\n",
    "\n",
    "        cv_score += fold_score\n",
    "\n",
    "    return cv_score/folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572\n",
      "572\n",
      "572\n",
      "572\n",
      "572\n",
      "[array([787, 824, 197,  92, 318, 668,   3, 332, 576, 845, 637, 374, 316,\n",
      "       663, 858, 574, 536, 329, 112, 696, 111, 834, 404, 632, 831, 262,\n",
      "        68, 640, 164, 291, 615, 275, 205,  93, 867, 172, 583,  11, 694,\n",
      "       652, 189, 389, 371,  52, 188, 730, 254, 710, 309, 861, 399, 150,\n",
      "        67, 199,  40,  78, 876,  98, 516, 549, 525, 105, 206, 340, 681,\n",
      "       544, 603,  57, 570, 102, 581, 520,  23, 723, 526, 733, 657, 577,\n",
      "       848, 173, 814, 236, 875, 537, 487, 145, 550, 446, 265,  44, 614,\n",
      "       660, 608, 671, 302, 642, 761, 634, 321, 726, 248, 838, 504, 247,\n",
      "       349, 528,  89, 461, 362, 357, 852, 556, 376, 724,  22, 843, 699,\n",
      "        81, 494, 271, 595, 119, 257, 179, 182, 378, 882,  62, 842, 484,\n",
      "       649, 706, 618, 390, 486, 423, 514, 452, 183, 132, 686, 626], dtype=int64), array([355, 664, 118, 817, 356, 373, 654, 540, 670, 877, 365, 512, 753,\n",
      "       844, 381, 586, 802, 865, 651, 408, 747, 856, 418, 162, 305, 701,\n",
      "       698,  79,  18, 762,  61,  25, 184, 242, 638, 243, 447, 366, 676,\n",
      "         2, 600, 450, 782, 472, 115, 237, 879, 571, 337, 297, 737, 871,\n",
      "       691, 421, 144, 853, 220,  37, 489, 796, 519, 721, 644, 382, 636,\n",
      "       360, 110, 672, 296, 345, 445, 758, 343, 788, 585, 276, 774, 117,\n",
      "       873, 204, 500,  80, 320, 239, 542, 442, 779, 864, 819, 346, 592,\n",
      "       414,  16, 599, 456, 133, 473, 772, 555, 745, 394, 165, 465, 281,\n",
      "       424, 808, 149, 294, 131,   9, 279, 380,  10, 437, 395, 510, 617,\n",
      "       886, 125, 258, 679, 804, 123, 369, 798, 812, 800,   7, 546, 323,\n",
      "       278,   6, 499, 822, 325, 627, 471, 251,   8, 210, 591,  70], dtype=int64), array([222, 704, 829,  51,  66, 227,  97, 841, 139, 708, 455, 170, 619,\n",
      "       854, 508, 193, 682, 263, 400,  73, 715, 769, 506, 786, 529, 561,\n",
      "       562, 458, 261, 398, 315, 299, 781, 725, 249, 307, 659,  99, 752,\n",
      "       635, 190,  94, 607, 397, 518, 203, 821, 127, 835,  58, 818, 728,\n",
      "       151, 308, 310, 763,  41, 597, 764, 700, 862, 436, 482, 717, 147,\n",
      "       392, 353, 860, 731, 106, 795, 887, 741, 810, 503, 645, 104, 221,\n",
      "       816, 569, 523, 252,  24, 820, 163, 207,  72,  54, 245, 224, 406,\n",
      "       604, 880, 751, 202, 157, 352, 673, 448, 476, 283, 744,   4, 565,\n",
      "       403,  84, 830, 285, 319, 108, 521, 827, 479, 582, 405, 148, 141,\n",
      "       716, 770, 336, 748, 771, 590, 505, 675, 628, 575, 689,  83, 379,\n",
      "       440, 313, 124,  27, 661,  85, 333, 746, 246, 789, 338, 501], dtype=int64), array([545,  13, 890, 688, 665,  33, 729, 114, 155, 736, 287, 480, 200,\n",
      "       579, 269, 750, 554,  15, 684, 720, 387, 687,  90, 641,  14, 441,\n",
      "       288, 869, 743, 391, 116, 666, 317, 572, 292, 823, 469, 794, 174,\n",
      "       587, 695, 719, 129, 435, 259, 427, 467,  60, 449, 534, 483, 836,\n",
      "       136, 192, 273, 363, 138, 478, 685, 412, 707, 167, 496,  74, 146,\n",
      "       219, 553, 331, 678, 610, 809, 401, 541, 616, 799,  71, 293, 620,\n",
      "       113, 621, 807, 135, 422, 187,  21, 885,  12, 312, 386, 539, 209,\n",
      "       348, 777, 754, 453, 177, 870, 811, 703, 755, 884, 662, 175,   0,\n",
      "       228, 889, 178, 713, 370, 874, 361, 232, 244, 630, 801, 344, 215,\n",
      "       797, 171, 705, 213,  63,   1,  43, 342, 216, 212,  96, 883, 605,\n",
      "       551, 432, 677, 253, 498, 558, 631,  53, 735, 535, 624, 100], dtype=int64), array([805, 463, 462, 513, 493,  49,  91, 160, 416, 169, 267,  39, 161,\n",
      "       326, 218, 290,  59, 460, 742, 492, 647, 120, 195, 749, 530, 840,\n",
      "        75, 103, 594,  30, 734, 803, 142, 791, 208, 327, 806, 152, 606,\n",
      "       813,  69, 443, 130, 372, 311, 655, 566, 280, 712, 230, 785, 609,\n",
      "       693, 850, 137,  86, 588, 477, 881, 434, 339, 509, 690, 622, 234,\n",
      "       438, 286, 765, 532, 780, 383, 402, 266, 851, 488, 702, 350, 377,\n",
      "       211, 191, 407, 623,  56, 429, 439, 233,  38, 543, 122, 134, 567,\n",
      "       833, 282, 238, 385, 268, 759, 430, 153, 396, 393, 580, 426,  88,\n",
      "       646, 847, 767, 314,  20, 757, 322, 433, 255, 491, 658, 474, 559,\n",
      "       866, 328, 419, 194, 417, 784, 857, 714, 225,  34, 683, 272,  35,\n",
      "       756, 217, 226, 625, 231, 872, 156,  50, 548, 515, 855, 775], dtype=int64)]\n",
      "0.535211267606\n",
      "0.528169014085\n",
      "0.471830985915\n",
      "0.570422535211\n",
      "0.577464788732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.53661971830985922"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossValidateScoreDataFrame(data, label, model, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a very simple cross validation function provided by sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SMS Spam with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## READING IN THE DATA\n",
    "df = pd.DataFrame.from_csv(\"SMSSpamCollection.tsv\",sep='\\t',header=0,index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                msg\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>spam</td>\n",
       "      <td>Thanks for your subscription to Ringtone UK yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>spam</td>\n",
       "      <td>07732584351 - Rodger Burns - MSG = We tried to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                msg\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "5   spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "8   spam  WINNER!! As a valued network customer you have...\n",
       "9   spam  Had your mobile 11 months or more? U R entitle...\n",
       "11  spam  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "12  spam  URGENT! You have won a 1 week FREE membership ...\n",
       "15  spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "19  spam  England v Macedonia - dont miss the goals/team...\n",
       "34  spam  Thanks for your subscription to Ringtone UK yo...\n",
       "42  spam  07732584351 - Rodger Burns - MSG = We tried to..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label=='spam'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                       5572\n",
       "unique                      5169\n",
       "top       Sorry, I'll call later\n",
       "freq                          30\n",
       "Name: msg, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.msg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the label into a binary variable\n",
    "# Remember the map function we learned before?\n",
    "df['label'] = df.label.map({'ham': 0 , 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                msg\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets by calling sklearn lib\n",
    "# by default, the data set is split into 0.75 (training) and 0.25 (testing)\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.msg, df.label, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179L,)\n",
      "710     4mths half price Orange line rental & latest c...\n",
      "3740                           Did you stitch his trouser\n",
      "2711    Hope you enjoyed your new content. text stop t...\n",
      "3155    Not heard from U4 a while. Call 4 rude chat pr...\n",
      "3748    Ãœ neva tell me how i noe... I'm not at home in...\n",
      "2389    wiskey Brandy Rum Gin Beer Vodka Scotch Shampa...\n",
      "3464    i am seeking a lady in the street and a freak ...\n",
      "772     Lol! U drunkard! Just doing my hair at d momen...\n",
      "3667    I'm turning off my phone. My moms telling ever...\n",
      "4955    U coming back 4 dinner rite? Dad ask me so i r...\n",
      "854     AH POOR BABY!HOPE URFEELING BETTERSN LUV! PROB...\n",
      "4079                  Gam gone after outstanding innings.\n",
      "2837                         Nice.nice.how is it working?\n",
      "1392                  Haha just kidding, papa needs drugs\n",
      "5533    Hey chief, can you give me a bell when you get...\n",
      "874     Ugh its been a long day. I'm exhausted. Just w...\n",
      "4408    Awesome, plan to get here any time after like ...\n",
      "3990    Ok lor. Anyway i thk we cant get tickets now c...\n",
      "1921                        Dont know you bring some food\n",
      "749     Is there a reason we've not spoken this year? ...\n",
      "2947                        make that 3! 4 fucks sake?! x\n",
      "2378    YES! The only place in town to meet exciting a...\n",
      "83                   You will be in the place of that man\n",
      "4668                           I send the print  outs da.\n",
      "128                                Are you there in room.\n",
      "4521    What to think no one saying clearly. Ok leave ...\n",
      "5090                             St andre, virgil's cream\n",
      "885     Yoyyooo u know how to change permissions for a...\n",
      "134     Sunshine Quiz Wkly Q! Win a top Sony DVD playe...\n",
      "3060    Dear all, as we know  &lt;#&gt; th is the  &lt...\n",
      "                              ...                        \n",
      "1031    Can not use foreign stamps in this country. Go...\n",
      "1110                      S s..first time..dhoni rocks...\n",
      "1888    Urgent! Please call 09061743811 from landline....\n",
      "3550    I got like $ &lt;#&gt; , I can get some more l...\n",
      "1527    Wow ... I love you sooo much, you know ? I can...\n",
      "753                           Dont gimme that lip caveboy\n",
      "3049             Die... Now i have e toot fringe again...\n",
      "2628    I know I'm lacking on most of this particular ...\n",
      "562                      Thanx 4 e brownie it's v nice...\n",
      "4764                           Prepare to be pleasured :)\n",
      "3562    Text BANNEDUK to 89555 to see! cost 150p texto...\n",
      "252     Wen ur lovable bcums angry wid u, dnt take it ...\n",
      "2516    Bognor it is! Should be splendid at this time ...\n",
      "2962    I'm doing da intro covers energy trends n pros...\n",
      "4453    I've told you everything will stop. Just dont ...\n",
      "5374    Do u konw waht is rael FRIENDSHIP Im gving yuo...\n",
      "5396             As in i want custom officer discount oh.\n",
      "1202                                 I know she called me\n",
      "3462    K.. I yan jiu liao... Sat we can go 4 bugis vi...\n",
      "2797    Tell your friends what you plan to do on Valen...\n",
      "4225    Double eviction this week - Spiral and Michael...\n",
      "144            I know you are. Can you pls open the back?\n",
      "5056    Am on a train back from northampton so i'm afr...\n",
      "2895                     K...k...yesterday i was in cbe .\n",
      "2763    ARR birthday today:) i wish him to get more os...\n",
      "905     We're all getting worried over here, derek and...\n",
      "5192    Oh oh... Den muz change plan liao... Go back h...\n",
      "3980    CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...\n",
      "235     Text & meet someone sexy today. U can find a d...\n",
      "5157                              K k:) sms chat with me.\n",
      "Name: msg, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1393L,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert the text into feature vectors which can be used for machine learning purposes.\n",
    "We will use the scikit function of CountVectorizer to 'convert text into a matrix of token counts'\n",
    "\n",
    " http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# start with a simple example\n",
    "train_simple = ['call you tonight',\n",
    "                'Call me a cab',\n",
    "                'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'cab', u'call', u'me', u'please', u'tonight', u'you']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data\n",
    "vect = CountVectorizer(decode_error = 'ignore')\n",
    "vect.fit(train_simple)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "train_simple_dtm = vect.transform(train_simple)\n",
    "train_simple_dtm.toarray()\n",
    "#train_simple_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(train_simple_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "test_simple = [\"please don't call me\"]\n",
    "test_simple_dtm = vect.transform(test_simple)\n",
    "test_simple_dtm.toarray()\n",
    "pd.DataFrame(test_simple_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer ( use variable name as vect)\n",
    "vect = CountVectorizer(decode_error = 'ignore')\n",
    "vect.fit(X_train)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform testing data into a document-term matrix: Use Variable name as test_dtm\n",
    "train_dtm = vect.transform(X_train)\n",
    "test_dtm = vect.transform(X_test)\n",
    "print test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the length  and names of the feature names\n",
    "train_features = vect.get_feature_names()\n",
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_features[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert train_dtm to a regular array\n",
    "train_arr = train_dtm.toarray()\n",
    "train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Revisit Numpy\n",
    "arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "print arr[0, 0]\n",
    "print arr[1, 3]\n",
    "print arr[0, :]\n",
    "print arr[:, 0]\n",
    "print np.sum(arr)\n",
    "print np.sum(arr,axis = 0)\n",
    "print np.sum(arr,axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise: calculate the number of tokens in the 0th message in train_arr\n",
    "print np.sum(train_arr[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# exercise: count how many times the 0th token appears across ALL messages in train_arr\n",
    "print np.sum(train_arr[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise: count how many times EACH token appears across ALL messages in train_arr\n",
    "print np.sum(train_arr, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise: create a DataFrame of tokens with their counts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the model with Naive Bayes Now\n",
    "\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train a Naive Bayes model using train_dtm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make predictions on test data using test_dtm\n",
    "preds = nb.predict(test_dtm)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare predictions to true labels\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, preds)\n",
    "print metrics.confusion_matrix(y_test, preds)\n",
    "# confusion matrix: http://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise: show the message text for the false positives\n",
    "X_test[(y_test == 0) & (preds == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# exercise: show the message text for the false negatives\n",
    "X_test[y_test > preds]\n",
    "# or\n",
    "X_test[(y_test == 1) & (preds == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## USING ALL DATA AND CROSS-VALIDATION and run NB again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## EXERCISE: CALCULATE THE 'SPAMMINESS' OF EACH TOKEN\n",
    "\n",
    "# create separate DataFrames for ham and spam ( df_ham and df_spam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# learn the vocabulary of ALL messages and save it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create document-term matrix of ham, then convert to a regular array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create document-term matrix of spam, then convert to a regular array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count how many times EACH token appears across ALL messages in ham_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count how many times EACH token appears across ALL messages in spam_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add one to ham counts and spam counts so that ratio calculations (below) make more sensse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate ratio of spam-to-ham for each token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# advanced: implement your own naive bayes classifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
